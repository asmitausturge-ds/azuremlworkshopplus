{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Azure Machine Learning Pipelines with AutoML\n",
        "\n",
        "In this demonstration, we will be looking at how to construct a training pipeline in Azure Machine Learning that includes data preparation, training with AutoML, and model registration.\n",
        "\n",
        "This demonstration is adapted from the following Azure ML pipeline example:\n",
        "\n",
        "[AutoML House Pricing Regression in Pipeline](https://github.com/Azure/azureml-examples/tree/main/sdk/python/jobs/pipelines/1h_automl_in_pipeline/automl-regression-house-pricing-in-pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ">[NOTE] Must use Python 3.10 SDK V2 for Lab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1670279800812
        }
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "\n",
        "from azure.ai.ml import MLClient, Input, command, Output\n",
        "from azure.ai.ml.dsl import pipeline\n",
        "from azure.ai.ml.automl import regression\n",
        "from azure.ai.ml.entities._job.automl.tabular import TabularFeaturizationSettings\n",
        "from azure.ai.ml.entities import Environment, AmlCompute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Note: AutoML steps in Pipelines are in Preview state at this time. Set AZURE_ML_CLI_PRIVATE_FEATURES_ENABLED to true to enable.\n",
        "import os\n",
        "os.environ[\"AZURE_ML_CLI_PRIVATE_FEATURES_ENABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get a reference to the Machine Learning workspace from config file created in previous steps\n",
        "In this step we are getting details of machine learning workspace previously created from the config file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The cell below can be executed if you are running the notebook locally in this machine and you created the workspace using the portal. Replace subscription-id, resource-group and workspace-name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1670279800944
        }
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1670279801078
        }
      },
      "outputs": [],
      "source": [
        "# Print workspace metadata\n",
        "ml_client.workspaces.get()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create compute cluster\n",
        "In the step below, we will create a compute target to run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Name assigned to the compute cluster\n",
        "cpu_compute_target = \"cpu-cluster\"\n",
        "\n",
        "try:\n",
        "    # let's see if the compute target already exists\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
        "    print(\n",
        "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
        "    )\n",
        "\n",
        "except Exception:\n",
        "    print(\"Creating a new cpu compute target...\")\n",
        "\n",
        "    # Let's create the Azure ML compute object with the intended parameters\n",
        "    cpu_cluster = AmlCompute(\n",
        "        name=cpu_compute_target,\n",
        "        # Azure ML Compute is the on-demand VM service\n",
        "        type=\"amlcompute\",\n",
        "        # VM Family\n",
        "        size=\"STANDARD_DS3_V2\",\n",
        "        # Minimum running nodes when there is no job running\n",
        "        min_instances=0,\n",
        "        # Nodes in cluster\n",
        "        max_instances=4,\n",
        "        # How many seconds will the node running after the job termination\n",
        "        idle_time_before_scale_down=180,\n",
        "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        "        tier=\"Dedicated\",\n",
        "    )\n",
        "\n",
        "    # Now, we pass the object to MLClient's create_or_update method\n",
        "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)\n",
        "\n",
        "print(\n",
        "    f\"AMLCompute with name {cpu_cluster.name} is created, the compute size is {cpu_cluster.size}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic pipeline job with AutoML regression task\n",
        "\n",
        "### Define Environment for data preprocessing step in the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1670279801970
        }
      },
      "outputs": [],
      "source": [
        "env_docker_conda = Environment(\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
        "    conda_file=\"./environment/preprocessing_env.yaml\",\n",
        "    name=\"pipeline-custom-environment\",\n",
        "    description=\"Environment created from a Docker image plus Conda environment.\",\n",
        ")\n",
        "ml_client.environments.create_or_update(env_docker_conda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1670279802999
        }
      },
      "outputs": [],
      "source": [
        "# Define pipeline\n",
        "@pipeline(\n",
        "    description=\"AutoML Car Price Regression Pipeline\",\n",
        ")\n",
        "def automl_regression(\n",
        "    regression_train_data, regression_validation_data, regression_test_data\n",
        "):\n",
        "    # define command function for preprocessing the model\n",
        "    preprocessing_command_func = command(\n",
        "        inputs=dict(\n",
        "            train_data=Input(type=\"mltable\"),\n",
        "            test_data=Input(type=\"mltable\"),\n",
        "            validation_data=Input(type=\"mltable\"),\n",
        "        ),\n",
        "\n",
        "        outputs=dict(\n",
        "            preprocessed_train_data=Output(type=\"mltable\"),\n",
        "            preprocessed_test_data=Output(type=\"mltable\"),\n",
        "            preprocessed_validation_data=Output(type=\"mltable\"),\n",
        "        ),\n",
        "        \n",
        "        code=\"./src/preprocess.py\",\n",
        "        command=\"python preprocess.py \"\n",
        "        + \"--train_data ${{inputs.train_data}} \"\n",
        "        + \"--validation_data ${{inputs.validation_data}} \"\n",
        "        + \"--test_data ${{inputs.test_data}} \"\n",
        "        + \"--preprocessed_train_data ${{outputs.preprocessed_train_data}} \"\n",
        "        + \"--preprocessed_validation_data ${{outputs.preprocessed_validation_data}} \"\n",
        "        + \"--preprocessed_test_data ${{outputs.preprocessed_test_data}}\",\n",
        "        environment=\"pipeline-custom-environment@latest\",\n",
        "    )\n",
        "\n",
        "    # define command task for preprocessing the data\n",
        "    preprocess_node = preprocessing_command_func(\n",
        "        train_data=regression_train_data,\n",
        "        test_data=regression_test_data,\n",
        "        validation_data=regression_validation_data,\n",
        "    )\n",
        "\n",
        "    # define the AutoML regression task with AutoML function\n",
        "    regression_node = regression(\n",
        "        primary_metric=\"r2_score\",\n",
        "        target_column_name=\"price\",\n",
        "        training_data=preprocess_node.outputs.preprocessed_train_data,\n",
        "        test_data=preprocess_node.outputs.preprocessed_test_data,\n",
        "        validation_data=preprocess_node.outputs.preprocessed_validation_data,\n",
        "        featurization=TabularFeaturizationSettings(mode=\"auto\"),\n",
        "        \n",
        "        # currently need to specify outputs \"mlflow_model\" explicitly to reference it in following nodes\n",
        "        enable_model_explainability=True,\n",
        "        outputs={\"best_model\": Output(type=\"mlflow_model\")},\n",
        "    )\n",
        "\n",
        "    # set limits & training\n",
        "    regression_node.set_limits(max_trials=5, max_concurrent_trials=2)\n",
        "    regression_node.set_training(\n",
        "        enable_stack_ensemble=True, enable_vote_ensemble=True\n",
        "    )\n",
        "\n",
        "    # define command function for registering the model\n",
        "    command_func = command(\n",
        "        inputs=dict(\n",
        "            model_input_path=Input(type=\"mlflow_model\"),\n",
        "            model_base_name=\"RULPredictInitial\",\n",
        "        ),\n",
        "        code=\"./src/register.py\",\n",
        "        command=\"python register.py \"\n",
        "        + \"--model_input_path ${{inputs.model_input_path}} \"\n",
        "        + \"--model_base_name ${{inputs.model_base_name}}\",\n",
        "        environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\",\n",
        "    )\n",
        "    \n",
        "    register_model = command_func(model_input_path=regression_node.outputs.best_model)\n",
        "\n",
        "\n",
        "pipeline_regression = automl_regression(\n",
        "    regression_train_data=Input(path=\"./data/car-price-data/training/\", type=\"mltable\"),\n",
        "    regression_validation_data=Input(\n",
        "        path=\"./data/car-price-data/validation/\", type=\"mltable\"\n",
        "    ),\n",
        "    regression_test_data=Input(path=\"./data/car-price-data/test/\", type=\"mltable\"),\n",
        ")\n",
        "\n",
        "# set pipeline level compute\n",
        "pipeline_regression.settings.default_compute = \"cpu-cluster\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submit pipeline job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1670279814839
        }
      },
      "outputs": [],
      "source": [
        "# submit the pipeline job\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline_regression, experiment_name=\"Car-Price-Regression-Experiment\"\n",
        ")\n",
        "pipeline_job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1670279579795
        }
      },
      "outputs": [],
      "source": [
        "# Wait until the job completes\n",
        "ml_client.jobs.stream(pipeline_job.name)"
      ]
    }
  ],
  "metadata": {
    "description": {
      "description": "Create pipeline with automl node"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
